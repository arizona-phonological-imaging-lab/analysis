import os, csv, unicodedata
import xlwt

##################################
#   Sam Johnston
#   11/21/13
#   Script to take a csv "stimulus master file" containing all stimuli and order it according to
#   the stimulus_response.csv file generated by the Ultrasound set-up, and create an excel file that
#   will contain all this information in order so that it can be filled out.  The purpose is to create
#   a csv file with all stimuli (and all sub-versions of the stimuli, eg "f" from "furich" and "ch"
#   from "furich") in the chronological order that is encoded within the stim-response file.  

#Fixes:
#Need to make sure that only numerical directories are added as sheets to the workbook (excel)

#########

def clean_Up(path):
    all_Files = os.listdir(path)
    x_Files = [j for j in all_Files if j.endswith('x.csv')]
    y_Files = [j for j in all_Files if j.endswith('y.csv')]
    files = x_Files + y_Files
    for filename in files:
        os.remove(filename)

def create_XL(path):
    all_Files = os.listdir(path)
    pre_Worksheets = [j for j in all_Files if j.endswith('y.csv')]
    excel = xlwt.Workbook(encoding='utf-8')

    for csv in pre_Worksheets:
        subject = csv[:2]
        sheet = excel.add_sheet(subject)
        info = open(csv, 'r').readlines()
        row_Num = 0
        for line in info:
            row = line.split('\t')
            col_Num = 0

            for cell in row:
                if col_Num == 80:
                    break
                try:
                    sheet.write(row_Num,col_Num,cell)
                    
                except UnicodeDecodeError:
                    sheet.write(row_Num,col_Num,'XXXX')
  
                col_Num += 1
            row_Num += 1
    excel.save('Identification_log_0.xls')

def write_Output(iteration, output):
    for line in iteration:
        output.write(line)
    output.write('\n')
    return output

def combine(path):
    #Get all files in the cwd, and grab all those ending with the custom .csv ending used above
    all_Files = os.listdir(path)
    CSVs = [k for k in all_Files if k.endswith('x.csv')]
    #iterate through all x.csv files, grab ones with 'a' (indicating first iteration for a given subject)
    for csv in CSVs:
        if csv[2] == 'a':
            #create an output file
            output = open(path+'/'+csv[:2]+'_stims_y.csv', 'w')
            #open the 'a' csv file for writing to a new output file
            first = open(csv, 'r').readlines()
            #write the new file line-by-line, and insert a return at the end - to separate iterations
            output = write_Output(first, output)
            #extract the subject number from filename to find iterations belonging with the above 'a' file
            subject_Num = csv[:2]
            b = False
            c = False
            #iterate through all csv's to find ones belonging to the above subject
            for csv_Match in CSVs:
                #critically, don't re-find and write the 'a' csv that was already written
                if csv_Match[:2] == subject_Num and csv_Match[2] == 'c':
                    iteration_C = open(csv_Match, 'r').readlines()
                    if b == True:
                        output = write_Output(iteration_C, output)
                    else:
                        c = True
                if csv_Match[:2] == subject_Num and csv_Match[2] == 'b':
                    #open the file and write it to new file
                    iteration_B = open(csv_Match, 'r').readlines()
                    output = write_Output(iteration_B, output)
                    if c == True:
                        output = write_Output(iteration_C, output)
                    else:
                        b = True
            output.close()
            continue

#Code to order stimuli in chronological order
def order_Stimuli(path, stim_Master):
    #finds all files/folders in cwd
    for dirnames in os.listdir(path):
        #we're only interested in folders, so if its a file, skip it
        if os.path.isfile(os.path.join(path, dirnames)):
            continue
        print dirnames

        #grabbing only the subject ID from the folder name (see below comment)
        i = dirnames[:2]
        #extract the subject ID (with iteration (letter)) from the folder name (e.g., 01a from "01a_062313")
        subject = dirnames[:3]
        print subject, 'subject'
        #specify the output csv files which will contain the ordered master set of stimuli
        output = open(path+'/'+dirnames[:3]+'_stim_order_x.csv', 'w')
        #specify the file containing the stimuli in order that can be referenced.
        try:
            stim_order = open(path+'/'+dirnames+'/stimulus_response.csv', 'rU').readlines()
        except IOError:     #this for the few directories without stim response files
            continue
        nextSound = 0
        olde_Word = 'X'
        #iterate through the stim_response file and write the stimuli (from and as listed in the stim_master file) in chron. order
        for j in range(len(stim_order)):
            line = stim_order[j]

            #ignore initial palate capture, start, and end rows
            if line == stim_order[0] or line == stim_order[1] or line == stim_order[2] or line == stim_order[3] or line == stim_order[-1]:
                continue

            words = line.split(',')
            word = words[1]
            word = "".join(c for c in unicodedata.normalize('NFD', (word).decode('utf-8')) if not unicodedata.combining(c))
            #something weird with "achlais" in stim_response files - this is just a hack 
            if 'achlais' in word:
                word = 'achlais'
            #I believe there were two empty lines within the SG stimuli list, which show up in the stim-response file
            #another hack
            if word == '':
                continue

            if word != olde_Word:
                nextSound = 0

            olde_Word = word
            templist = []
            y = -1
            #iterate through stim-master file to find matches, and then write them to the output (in the chron order
            #evident in the stim-response file)
            base_File = csv.reader(stim_Master)

            for cells in base_File:
                y+=1
                temptemplist = []
                temptemplist.append(i)
                temptemplist.append(subject)

                #split the row, and add subject and iteration identifiers
                if len(cells)<3:
                    continue

                #only allow headers and palate frames before the first iteration for a subject
                if subject[-1] == 'a' and j == 4:
                    if y < 2:
                        newRow = ''
                        for cell in cells:
                            newRow += cell.rstrip()+'\t'
                        output.write((newRow[:-1]+'\r\n'))       #include the -1 to take off the 'tab' from above line at end
                        continue

                    if y < 5 and y > 1:
                        cells[0] = str(i)
                        cells[1] = subject
                        new_Row = ''
                        for cell in cells[:4]:
                            new_Row += cell.rstrip()+'\t'
                        new_Row += '\r\n'
                        output.write(new_Row)
                        continue

                cells[0] = str(i)
                cells[1] = subject
                word = word.replace(' ', '-')
                cells[2] = cells[2].replace(' ','-')

                #using the templist allows all sounds within a stimulus (see "furich" in description) to occur together
                if cells[2] == word:
                    temptemplist.append(cells[2].rstrip())
                    orthography = open('Words_Sounds.txt', 'rU').readlines()

                    for z in range(len(orthography)-1): #adds orthography used in TextGrids

                        if z+nextSound == len(orthography):
                            break

                        horizontal = orthography[z]
                        horizontal = horizontal.split('\t')        #horizontal is the row, split into a list
                        ortho_Word = horizontal[0]      #finds the word of interest at the first index location

                        if ortho_Word == word:          #check if it is equal to work from stim_List (equal to word in base excel as well)
                            horizontal = orthography[z+nextSound].split('\t')     #if it is equal, rereference horizontal; use z, + nextSound in instance of mutliple sounds for a given word

                            ortho_Study = horizontal[1]
                            ortho_Spelling = horizontal[2]

                            temptemplist.append(ortho_Study)
                            temptemplist.append(cells[4])

                            temptemplist.append(ortho_Spelling)

                            templist.append(temptemplist)
                            y+=1
                            j+=1
                            nextSound += 1

                            break
  
            #converts list to tab delinieated string and writes it to the output file
            for instance in templist:
                new_Row = ''
                for cell in instance:
                    new_Row += cell.rstrip()+'\t'
                new_Row = (new_Row[:-1]+'\r\n')     #cut off trailing \t, add newline

                output.write(new_Row)
        output.close()

def main():
    #get path of current working directory
    path = os.getcwd()
    #find the stimulus master file (contains all stimuli, divided into sounds of interest;the SoI critically are ordered chronologically)
    stim_Master = open('Identification_log.csv', 'rU').readlines()
    #Code for ordering stimuli chronologically, according to stim_response file
    order_Stimuli(path, stim_Master)
    #Code to combine different iterations of csv files into one csv (so 10a, 10b, and 10c are all in the same document.
    #if all iterations already in one file, no need for this code
    combine(path)
    #Code to combine these new files (containing all iterations) into a singular excel file with a worksheet per subject
    create_XL(path)
    #Code to "clean up" all the csv files
    clean_Up(path)
    
main()
